{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5437c427",
   "metadata": {},
   "source": [
    "# The actual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cf7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 488 performers\n"
     ]
    }
   ],
   "source": [
    "# Load performer list\n",
    "with open('rock_artists/PERFORMER_LIST.txt', 'r', encoding='utf-8') as f:\n",
    "    performers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "performer_set = set(performers)\n",
    "\n",
    "# Create mapping: sanitized filename -> original performer name\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"Same function from download\"\"\"\n",
    "    filename = re.sub(r'\\s*\\([^)]*\\)\\s*', '', filename)\n",
    "    replacements = {\n",
    "        '/': '_', '\\\\': '_', ':': '_', '*': '_', '?': '_',\n",
    "        '\"': '_', '<': '_', '>': '_', '|': '_', '!': '', '.': '_'\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        filename = filename.replace(old, new)\n",
    "    filename = re.sub(r'_+', '_', filename)\n",
    "    return filename.strip('_')\n",
    "\n",
    "filename_to_performer = {}\n",
    "for performer in performers:\n",
    "    sanitized = sanitize_filename(performer.replace(' ', '_'))\n",
    "    filename_to_performer[sanitized] = performer\n",
    "\n",
    "print(f\"Loaded {len(performers)} performers\")\n",
    "print(f\"Created {len(filename_to_performer)} filename mappings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a710d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(content):\n",
    "    \"\"\"\n",
    "    Count words in wiki content, excluding markup.\n",
    "    Simple approach: just count whitespace-separated tokens that look like words.\n",
    "    \"\"\"\n",
    "    # Remove wiki templates {{...}}\n",
    "    content = re.sub(r'\\{\\{[^}]*\\}\\}', '', content)\n",
    "    # Remove HTML tags\n",
    "    content = re.sub(r'<[^>]+>', '', content)\n",
    "    # Remove wiki links but keep text: [[Link|Text]] becomes Text\n",
    "    content = re.sub(r'\\[\\[([^\\]|]+\\|)?([^\\]]+)\\]\\]', r'\\2', content)\n",
    "    # Split by whitespace and count\n",
    "    words = content.split()\n",
    "    return len(words)\n",
    "\n",
    "def extract_wiki_links(content):\n",
    "    \"\"\"\n",
    "    Extract all wiki links from the content.\n",
    "    Pattern explanation:\n",
    "    - \\[\\[ matches opening [[\n",
    "    - ([^\\]|]+) captures everything except ] or |\n",
    "    - (?:\\|[^\\]]+)? optionally matches |DisplayText (but we don't capture it)\n",
    "    - \\]\\] matches closing ]]\n",
    "    \"\"\"\n",
    "    pattern = r'\\[\\[([^\\]|]+)(?:\\|[^\\]]+)?\\]\\]'\n",
    "    links = re.findall(pattern, content)\n",
    "    return [link.strip() for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "437e9753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network from all performer pages...\n",
      "This will take a couple minutes...\n",
      "\n",
      "Processed 50 pages, 711 edges so far...\n",
      "Processed 100 pages, 1425 edges so far...\n",
      "Processed 150 pages, 2200 edges so far...\n",
      "Processed 200 pages, 2870 edges so far...\n",
      "Processed 250 pages, 3725 edges so far...\n",
      "Processed 300 pages, 4543 edges so far...\n",
      "Processed 350 pages, 5331 edges so far...\n",
      "Processed 400 pages, 6004 edges so far...\n",
      "Processed 450 pages, 6789 edges so far...\n",
      "\n",
      "============================================================\n",
      "Network built!\n",
      "Nodes: 584\n",
      "Edges: 7267\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "pages_dir = 'rock_artists/pages'\n",
    "\n",
    "print(\"Building network from all performer pages...\")\n",
    "print(\"This will take a couple minutes...\\n\")\n",
    "\n",
    "processed = 0\n",
    "edges_created = 0\n",
    "\n",
    "for filename in os.listdir(pages_dir):\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "    \n",
    "    # Read the page\n",
    "    filepath = os.path.join(pages_dir, filename)\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Figure out which performer this is\n",
    "    # filename is like \"The_Beatles.txt\", we need \"The Beatles (band)\" or similar\n",
    "    # For now, let's use the filename without .txt as the node name\n",
    "    performer_name = filename[:-4].replace('_', ' ')\n",
    "    \n",
    "    # Count words\n",
    "    word_count = count_words(content)\n",
    "    \n",
    "    # Add node with word count attribute\n",
    "    G.add_node(performer_name, content_length=word_count)\n",
    "    \n",
    "    # Extract and filter links\n",
    "    all_links = extract_wiki_links(content)\n",
    "    performer_links = [link for link in all_links if link in performer_set]\n",
    "    \n",
    "    # Add edges (remove duplicates with set())\n",
    "    for target in set(performer_links):\n",
    "        G.add_edge(performer_name, target)\n",
    "        edges_created += 1\n",
    "    \n",
    "    processed += 1\n",
    "    if processed % 50 == 0:\n",
    "        print(f\"Processed {processed} pages, {edges_created} edges so far...\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Network built!\")\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca158e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
