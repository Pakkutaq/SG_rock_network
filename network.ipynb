{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5437c427",
   "metadata": {},
   "source": [
    "# The actual network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eec8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3cf7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 488 performers\n",
      "Created 485 filename mappings\n"
     ]
    }
   ],
   "source": [
    "# Load performer list\n",
    "with open('rock_artists/PERFORMER_LIST.txt', 'r', encoding='utf-8') as f:\n",
    "    performers = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "performer_set = set(performers)\n",
    "\n",
    "# Create mapping: sanitized filename -> original performer name\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"Same function from download\"\"\"\n",
    "    filename = re.sub(r'\\s*\\([^)]*\\)\\s*', '', filename)\n",
    "    replacements = {\n",
    "        '/': '_', '\\\\': '_', ':': '_', '*': '_', '?': '_',\n",
    "        '\"': '_', '<': '_', '>': '_', '|': '_', '!': '', '.': '_'\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        filename = filename.replace(old, new)\n",
    "    filename = re.sub(r'_+', '_', filename)\n",
    "    return filename.strip('_')\n",
    "\n",
    "filename_to_performer = {}\n",
    "for performer in performers:\n",
    "    sanitized = sanitize_filename(performer.replace(' ', '_'))\n",
    "    filename_to_performer[sanitized] = performer\n",
    "\n",
    "print(f\"Loaded {len(performers)} performers\")\n",
    "print(f\"Created {len(filename_to_performer)} filename mappings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a710d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(content):\n",
    "    \"\"\"\n",
    "    Count words in wiki content, excluding markup.\n",
    "    Simple approach: just count whitespace-separated tokens that look like words.\n",
    "    \"\"\"\n",
    "    # Remove wiki templates {{...}}\n",
    "    content = re.sub(r'\\{\\{[^}]*\\}\\}', '', content)\n",
    "    # Remove HTML tags\n",
    "    content = re.sub(r'<[^>]+>', '', content)\n",
    "    # Remove wiki links but keep text: [[Link|Text]] becomes Text\n",
    "    content = re.sub(r'\\[\\[([^\\]|]+\\|)?([^\\]]+)\\]\\]', r'\\2', content)\n",
    "    # Split by whitespace and count\n",
    "    words = content.split()\n",
    "    return len(words)\n",
    "\n",
    "def extract_wiki_links(content):\n",
    "    \"\"\"\n",
    "    Extract all wiki links from the content.\n",
    "    Pattern explanation:\n",
    "    - \\[\\[ matches opening [[\n",
    "    - ([^\\]|]+) captures everything except ] or |\n",
    "    - (?:\\|[^\\]]+)? optionally matches |DisplayText (but we don't capture it)\n",
    "    - \\]\\] matches closing ]]\n",
    "    \"\"\"\n",
    "    pattern = r'\\[\\[([^\\]|]+)(?:\\|[^\\]]+)?\\]\\]'\n",
    "    links = re.findall(pattern, content)\n",
    "    return [link.strip() for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437e9753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network from all performer pages...\n",
      "This will take a couple minutes...\n",
      "\n",
      "Processed 50 pages, 711 edges so far...\n",
      "Processed 100 pages, 1425 edges so far...\n",
      "Processed 150 pages, 2200 edges so far...\n",
      "Processed 200 pages, 2870 edges so far...\n",
      "Processed 250 pages, 3725 edges so far...\n",
      "Processed 300 pages, 4543 edges so far...\n",
      "Processed 350 pages, 5331 edges so far...\n",
      "Processed 400 pages, 6004 edges so far...\n",
      "Processed 450 pages, 6789 edges so far...\n",
      "\n",
      "============================================================\n",
      "Network built!\n",
      "Nodes: 488\n",
      "Edges: 7267\n"
     ]
    }
   ],
   "source": [
    "# Create directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "pages_dir = 'rock_artists/pages'\n",
    "\n",
    "print(\"Building network from all performer pages...\")\n",
    "print(\"This will take a couple minutes...\\n\")\n",
    "\n",
    "processed = 0\n",
    "edges_created = 0\n",
    "\n",
    "for filename in os.listdir(pages_dir):\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "    \n",
    "    # Read the page\n",
    "    filepath = os.path.join(pages_dir, filename)\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Figure out which performer this is\n",
    "    # filename is like \"The_Beatles.txt\", we need \"The Beatles (band)\" or similar\n",
    "    # For now, let's use the filename without .txt as the node name\n",
    "    base_filename = filename[:-4]  # Remove .txt\n",
    "    performer_name = filename_to_performer.get(base_filename, base_filename.replace('_', ' '))\n",
    "    \n",
    "    # Count words\n",
    "    word_count = count_words(content)\n",
    "    \n",
    "    # Add node with word count attribute\n",
    "    G.add_node(performer_name, content_length=word_count)\n",
    "    \n",
    "    # Extract and filter links\n",
    "    all_links = extract_wiki_links(content)\n",
    "    performer_links = [link for link in all_links if link in performer_set]\n",
    "    \n",
    "    # Add edges (remove duplicates with set())\n",
    "    for target in set(performer_links):\n",
    "        G.add_edge(performer_name, target)\n",
    "        edges_created += 1\n",
    "    \n",
    "    processed += 1\n",
    "    if processed % 50 == 0:\n",
    "        print(f\"Processed {processed} pages, {edges_created} edges so far...\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Network built!\")\n",
    "print(f\"Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Quick visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Use spring layout (will take a moment to compute)\n",
    "pos = nx.spring_layout(G, k=0.5, iterations=50)\n",
    "\n",
    "# Draw nodes (small size since there are many)\n",
    "nx.draw_networkx_nodes(G, pos, node_size=20, node_color='lightblue', alpha=0.6)\n",
    "\n",
    "# Draw edges (very thin and transparent)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.1, arrows=False, width=0.5)\n",
    "\n",
    "plt.title(f\"Rock Performers Network\\n{G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ca158e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolated nodes (no connections): 4\n",
      "\n",
      "Isolated performers:\n",
      "  - The B-52's\n",
      "  - Dr. Hook & the Medicine Show\n",
      "  - Jet (Australian band)\n",
      "  - Van Zant (band)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Check for isolated nodes\n",
    "\n",
    "# Find nodes with no connections (no in-degree AND no out-degree)\n",
    "isolated_nodes = [node for node in G.nodes() if G.degree(node) == 0]\n",
    "\n",
    "print(f\"Isolated nodes (no connections): {len(isolated_nodes)}\")\n",
    "if isolated_nodes:\n",
    "    print(\"\\nIsolated performers:\")\n",
    "    for node in isolated_nodes[:10]:\n",
    "        print(f\"  - {node}\")\n",
    "    if len(isolated_nodes) > 10:\n",
    "        print(f\"  ... and {len(isolated_nodes) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9ffad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing isolated nodes: 484 nodes\n",
      "\n",
      "Largest weakly connected component:\n",
      "  Nodes: 484\n",
      "  Edges: 7267\n",
      "\n",
      "Final network: 484 nodes, 7267 edges\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Remove isolated nodes and extract largest component\n",
    "\n",
    "# Remove isolated nodes\n",
    "G.remove_nodes_from(isolated_nodes)\n",
    "print(f\"After removing isolated nodes: {G.number_of_nodes()} nodes\")\n",
    "\n",
    "# Extract largest weakly connected component\n",
    "# (weakly connected means ignoring edge direction)\n",
    "largest_wcc = max(nx.weakly_connected_components(G), key=len)\n",
    "G_largest = G.subgraph(largest_wcc).copy()\n",
    "\n",
    "print(f\"\\nLargest weakly connected component:\")\n",
    "print(f\"  Nodes: {G_largest.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G_largest.number_of_edges()}\")\n",
    "\n",
    "# This is now our final network for analysis\n",
    "G = G_largest\n",
    "print(f\"\\nFinal network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "860d5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved network as GraphML\n",
      "\n",
      "Network Summary:\n",
      "  Nodes: 484\n",
      "  Edges: 7267\n",
      "  Density: 0.0311\n",
      "  Is directed: True\n",
      "\n",
      "Verification - loaded network has 484 nodes, 7267 edges\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save the network\n",
    "\n",
    "# Save as GraphML (good format, preserves attributes)\n",
    "nx.write_graphml(G, 'rock_artists/rock_network.graphml')\n",
    "print(\"Saved network as GraphML\")\n",
    "\n",
    "# Also save basic info\n",
    "print(f\"\\nNetwork Summary:\")\n",
    "print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  Edges: {G.number_of_edges()}\")\n",
    "print(f\"  Density: {nx.density(G):.4f}\")\n",
    "print(f\"  Is directed: {G.is_directed()}\")\n",
    "\n",
    "# Verify we can load it back\n",
    "G_test = nx.read_graphml('rock_artists/rock_network.graphml')\n",
    "print(f\"\\nVerification - loaded network has {G_test.number_of_nodes()} nodes, {G_test.number_of_edges()} edges\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
